from FunctionsModel import *

parser.add_argument('-imt', "--int-mes-types", default='PGA SA(0.3) SA(0.6) SA(1.0)', type=str, help="enter the unique intensity measurement types in the model data with a space in between each type as a string")
parser.add_argument('-F', "--data-path", default="global_vulnerability_model", help = "input name of folder containing the vulnerability functions")
parser.add_argument('-cov', "--coverage-type", default='structural', help = "input structural, contents or non_structural")

def directories(rootdir, coverage_type):
    location_dict = {}
    for file in Path(rootdir).glob('**/*.xml'):
        filepath = Path(file).absolute()
        cov_type_path = Path(file).name
        if PurePosixPath(cov_type_path).stem == f"vulnerability_{coverage_type}":
            location_continent = Path(file).parent.parent.name
            location_country = Path(file).parent.name
            location_dict [location_continent, location_country] = filepath
    return location_dict

def create_vuln_ids(location_list, height_dict, occup_dict, constr_dict, countr_dict):
    vuln_ids = {}
    cur_vuln_id = 1    

    for location in location_list:
    # for country in location_list:
        pathway = location_list[location]
        # pathway = location_list[country]
        tree = ET.parse(pathway)
        root = tree.getroot()
        for i in range (1, len(root[0])):
            taxonomy = root[0][i].attrib['id']
            tax = taxonomy.split('/')
            # example of tax: ['CR', 'LDUAL+CDL+DUM', 'H1', 'RES']
            # if (continent, country, taxonomy) not in vuln_ids:
            if (location, taxonomy) not in vuln_ids:
                # vuln_ids[(continent, country, taxonomy)] = cur_vuln_id
                vuln_ids[(location, taxonomy)] = cur_vuln_id
                cur_vuln_id += 1
                for (attribute2, peril_type) in constr_dict:
                    if attribute2 in tax:
                        attribute2_id = constr_dict[attribute2, peril_type]
                        peril_id = peril_type
                for attribute6 in occup_dict:
                    if attribute6 in tax:
                        attribute6_id = occup_dict[attribute6]
                for attribute4 in height_dict:
                    if attribute4 in tax:
                        no_storeys = height_dict[attribute4]
                country_code = countr_dict[country]
                id_dict = {
                    # "vulnerability_id": vuln_ids[(continent, country, taxonomy)],
                    "vulnerability_id": vuln_ids[(country, taxonomy)],
                    "peril_id": peril_id,
                    "country_code": country_code,
                    "taxonomy": taxonomy,
                    "node_id": i,
                    "attribute2_id": attribute2_id,
                    "attribute4_id": no_storeys,
                    "attribute6_id": attribute6_id
                }
                yield id_dict

def get_vuln_ids(vulns_df, countr_dict, location_dict, vuln_ids_path):
    header = True
    vuln_dict = {}
    # Reverse key and values in countr_dict 
    rev_countr_dict = {countr_dict[country]: country for country in countr_dict}
    # Map country to continent
    countr_to_cont = {country: continent for (continent, country) in location_dict}

    # Open vulnerability dictionary file from keys_data folder
    """ with open(vuln_ids_path) as file:
    # Read in bins data from opened file
        for line in file: 
    for row in vulns_df.iterrows():
        # data = line.strip().split(',')
        if header == True:    
            vuln_id = data.index('vulnerability_id')
            vuln_country_code = data.index('country_code')
            vuln_taxonomy = data.index('taxonomy')
            vuln_node_id = data.index('node_id') 
            header = False
        else:
            country_code = data[vuln_country_code]
            country = rev_countr_dict[country_code]
            continent = countr_to_cont[country]
            vuln_dict[(continent, country, data[vuln_taxonomy], data[vuln_node_id])] = data[vuln_id] """
    for index, row in vulns_df.iterrows():
        vuln_id = row['vulnerability_id']
        vuln_country_code = row['country_code']
        vuln_taxonomy = row['taxonomy']
        vuln_node_id = row['node_id']
        country = rev_countr_dict[vuln_country_code]
        continent = countr_to_cont[country]
        vuln_dict[(continent, country, vuln_taxonomy, vuln_node_id)] = [vuln_id]
    return vuln_dict

def main(working_folder, num_damage_bins, coverage_type, oasis_model_folder, data_path, country_specific, continent_specific, int_mes_types):
    t_zero = time.time()
    incr = 1/num_damage_bins
    
    # only true if both true - check documentation
    if continent_specific and country_specific:
        print ("Cannot input both specific countries and continents")
        sys.exit()
    
    # produces string that is the name of the folder in which all the model's data and code is contained - default is 'VulnerabilityLibrary'
    path_stem = init_run(working_folder)

    # hazard intensity bins created and a dictionary is outputted 
    int_bins, int_mp_vals = init_int_bins(path_stem)
    int_mes_types = int_mes_types.split()
    int_bins_dict = create_int_bins(int_bins, int_mp_vals, int_mes_types)

    int_bins_df = pd.DataFrame(int_bins_dict)
    int_bin_dict_path = PurePath.joinpath(path_stem, int_dict_path)
    int_bins_df.to_csv(int_bin_dict_path, index=False)
    
    # damage bin list does not have repeated start or end - length 102 - same as number of damage bins
    damage_bins, damage_bins_list = init_damage_bins(incr)
    dam_bins_dict = create_damage_bins(damage_bins)

    damage_bins_df = pd.DataFrame(dam_bins_dict)
    damage_bins_path = PurePath.joinpath(path_stem, oasis_model_folder, dam_bin_path)
    damage_bins_df.to_csv(damage_bins_path, index=False)
    
    # check that continent/country specified is within data - also prevents entering a country name using the continent arge parse command and vice versa
    # location[0] and location[1] refer to continent and country respectively
    for count, cont in zip (country_specific, continent_specific):
        if count and (cont not in [location[0] for (location, filepath) in location_dict.items()]):
            print ("Must specify continent within model data")
            sys.exit()
        if cont and (count not in [location[1] for (location, filepath) in location_dict.items()]):
            print ("Must specify country within model data")
            sys.exit()

    # creates dictionary to pair attrbiutes with attribute ids
    height_path = PurePath.joinpath(path_stem, oasis_model_folder, rel_height_path)
    occup_path = PurePath.joinpath(path_stem, oasis_model_folder, rel_occup_path)
    constr_path = PurePath.joinpath(path_stem, oasis_model_folder, rel_constr_path)
    countr_path = PurePath.joinpath(path_stem, oasis_model_folder, rel_countr_path)

    height_dict = get_codes('attribute4', height_path)
    occup_dict = get_codes('attribute6', occup_path)
    constr_dict = get_codes('attribute2', constr_path, extra_keys_in = ['peril_id'])
    countr_dict = get_codes('country', countr_path, id_suffix='_code')

    rootdir = PurePath.joinpath(path_stem, data_path)
    # list of all locations with data in vulnerability models folder stored in dictionary as key and the value is the relative path
    location_dict = directories(rootdir, coverage_type)
    # removes continent key in the location_dict dictionary
    location_list = {country: location_list[(continent, country)] for (continent, country) in location_list}

    # output vulnerability id dictionary - each type of building within each country given unique id 
    vuln_ids = create_vuln_ids(location_list, height_dict, occup_dict, constr_dict, countr_dict)
    vulns_df = pd.DataFrame(vuln_ids)

    vuln_dict_path = PurePath.joinpath(path_stem, oasis_model_folder, vuln_dict_path)
    vulns_df.to_csv(vuln_dict_path, index=False)
    # node_id is not used in vulnerability_dict - it is useful for backend purposes
    # vulns_df.drop(labels='node_id', axis=1, inplace=False).to_csv(vuln_ids_path, index=False)

    # create dictionary with location, taxonomy, node_id as keys and the vulnerability id as the value 
    # note: taxonomy and node_id within each country correspond
    vuln_dict = get_vuln_ids(vulns_df, countr_dict, location_dict, vuln_dict_path)

    t_zero = time.time() - t_zero
    t_one=  time.time()
    with open (PurePath.joinpath(path_stem, oasis_model_folder, vulnerability_path), 'wb') as dict_file:
        header = True
        current_location = ('','')
        
        for j, (continent, country, taxonomy, node_id) in enumerate(vuln_dict):
            # not () and not () functions as NAND logic gate
            if (not(country_specific) and not(continent_specific)) or continent in continent_specific or country in country_specific:
                if country != current_location:
                    current_location = country
                    pathway = location_list[country]
                    tree = ET.parse(pathway)
                    root = tree.getroot()
                # node ID easier to understand than using complication logic (num = j-1 and i = j-m)
                print ('running', continent, country, ': ', node_id, '/', len(root[0])-1)
                intensity_measure = root[0][int(node_id)][0].attrib['imt']
                # syntax notes
                    # empty space is default value for split - read documenation
                    # map is generator - used to replace entire function (ref below) used to convert list of strings to floats
                    # int_vals, mean_LRs, std_dev_list, int_bin_list, int_mp_list = float_conversion(int_vals, mean_LRs, coeff_vars, int_bin_vals, int_mp_vals)
                int_vals = list(map(float,root[0][int(node_id)][0].text.split()))
                mean_LRs = list(map(float,root[0][int(node_id)][1].text.split()))
                coeff_vars = list(map(float,root[0][int(node_id)][2].text.split()))
                std_devs = [mean_LR*coeff_var for mean_LR, coeff_var in zip(mean_LRs, coeff_vars)]
                
                # return list of bin index values for each intensity value used to calulcate a probability
                bin_index_list = get_bin_index(int_bins, int_mp_vals, int_mes_types, intensity_measure)
                # vulnerability id can be found with either taxonomy or node id 
                vuln_id = vuln_dict[(continent, country, taxonomy, node_id)]
                # create vulnerability file with vulnerability ids, correct intensity bin indexes and damage bin indexes
                vuln_data = create_vuln_dict (vuln_id, bin_index_list, damage_bins)
                vuln_temp_df = pd.DataFrame(vuln_data)

                # function compute_probs() computes probabilities using beta distribution
                probs_data = compute_probs(int_vals, int_mp_vals, mean_LRs, std_devs, damage_bins_list)
                probs_df = pd.DataFrame(probs_data)

                vuln_df = pd.concat([vuln_temp_df, probs_df], axis = 1)        
                vuln_df.to_csv(dict_file, index=False, header=header)       
                header = False
        print (t_zero)
        print(time.time() - t_one)

kwargs = vars(parser.parse_args())
main(**kwargs)