""" global flood damage functions """

# implement functions originally used for the code to compute the GEM Vulnerability Model 
from FunctionsModel import *

parser.add_argument('-imt', "--int-mes-types", default='flood_depth_metres', type=str, help="enter the unique intensity measurement types in the model data")
parser.add_argument('-F', "--data-path", default="global_flood_depth-damage_functions.xlsx", help = "input name of file containing the vulnerability functions")

def create_vuln_ids(region_list, occup_dict, damage_classes):
    vuln_ids = {}
    cur_vuln_id = 1    

    for damage_class, continent in zip(damage_classes, region_list):
        # if (continent, country, taxonomy) not in vuln_ids:
        if (continent, damage_class) not in vuln_ids:
            # vuln_ids[(continent, country, taxonomy)] = cur_vuln_id
            vuln_ids[(continent, damage_class)] = cur_vuln_id
            cur_vuln_id += 1
            for attribute6 in damage_classes:
                print(damage_classes)
                continue
                if attribute6 in occup_dict:
                    attribute6_id = occup_dict[attribute6]
            id_dict = {
                "vulnerability_id": vuln_ids[(continent, damage_class)],
                "location": continent,
                "attribute6_id": 1
            }
            yield id_dict

def get_vuln_ids(vulns_df):
    header = True
    vuln_dict = {}

    for index, row in vulns_df.iterrows():
        vuln_id = row['vulnerability_id']
        vuln_cont = row['location']
        vuln_class = row['damage_class']
        vuln_dict[(vuln_cont, vuln_class)] = [vuln_id]
    return vuln_dict

def use_excel(data_path):
    df_xlsx = pd.ExcelFile(data_path)
    damage_classes = []
    int_bin_list = []
    region_list = []
    probs = []
    std_devs = []
    data = pd.read_excel(df_xlsx, 'Damage functions', na_filter=False, header=[1,2])

    for row in data['Damage\nclass']:
        if row:
            print(row)

    for row in data['Flood depth,\n[m]'].iloc[:, [0][0]]:
        int_bin_list.append(row)

    for region in data['Damage function']:
        region_list.append(region)
    
    for region in region_list:
        region_probs = []
        region_std_devs = []

        for prob in data['Damage function'][region]:
            if type(prob) == int or type(prob) == float:
                region_probs.append(prob)
        probs.append(region_probs)
        for std_dev in data['Standard deviation'][region]:
            if type(std_dev) == int or type(std_dev) == float:
                region_std_devs.append(std_dev)
        std_devs.append(region_std_devs)

    return damage_classes, int_bin_list, region_list, probs, std_devs

def main(working_folder, num_damage_bins, oasis_model_folder, data_path, country_specific, continent_specific, int_mes_types):
    t_zero = time.time()
    incr = 1/num_damage_bins
    int_mes_types = int_mes_types.split()

    # only true if both true - check documentation
    if continent_specific:
        print ("Cannot input both specific countries and continents")
        sys.exit()
    
    # produces string that is the name of the folder in which all the model's data and code is contained - default is 'VulnerabilityLibrary'
    path_stem = init_run(working_folder)

    # hazard intensity bins created and a dictionary is outputted 
    int_bins, int_mp_vals = init_int_bins(path_stem)
    int_bins_dict = create_int_bins(int_bins, int_mp_vals, int_mes_types)

    int_bins_df = pd.DataFrame(int_bins_dict)
    int_bin_dict_path = PurePath.joinpath(path_stem, int_dict_path)
    int_bins_df.to_csv(int_bin_dict_path, index=False)
    
    # damage bin list does not have repeated start or end - length 102 - same as number of damage bins
    damage_bins, damage_bins_list = init_damage_bins(incr)
    dam_bins_dict = create_damage_bins(damage_bins)

    damage_bins_df = pd.DataFrame(dam_bins_dict)
    damage_bins_path = PurePath.joinpath(path_stem, oasis_model_folder, dam_bin_path)
    damage_bins_df.to_csv(damage_bins_path, index=False)

    # list of all locations with data in vulnerability models folder stored in dictionary as key and the value is the relative path
    rootdir = PurePath.joinpath(path_stem, data_path)
    damage_classes, int_vals, region_list, int_vals_list, std_devs_list = use_excel(rootdir)
    print (int_vals)
    return "nothing"
    
    # check that continent/country specified is within data - also prevents entering a country name using the continent arge parse command and vice versa
    for cont in continent_specific:
        if cont not in [location for location in region_list]:
            print ("Must specify continent within model data")
            sys.exit()

    # creates dictionary to pair attrbiutes with attribute ids
    occup_path = PurePath.joinpath(path_stem, oasis_model_folder, rel_occup_path)
    occup_dict = get_codes('attribute6', occup_path)
    
    # output vulnerability id dictionary - each type of building within each country given unique id 
    vuln_ids = create_vuln_ids(region_list, occup_dict, damage_classes)
    vulns_df = pd.DataFrame(vuln_ids)
    vuln_ids_path = PurePath.joinpath(path_stem, oasis_model_folder, vuln_dict_path)
    vulns_df.to_csv(vuln_ids_path, index=False)

    # create dictionary with location, and building type as keys and the vulnerability id as the value 
    vuln_dict = get_vuln_ids(vulns_df)

    t_zero = time.time() - t_zero
    return "nothing"
    t_one=  time.time()
    with open (PurePath.joinpath(path_stem, oasis_model_folder, vulnerability_path), 'wb') as dict_file:
        header = True
        current_location = ('','')
        length = len(vuln_dict)
        
        for j, (continent, damage_class), in enumerate(zip(vuln_dict)):
            if (not continent_specific) or (continent in continent_specific):
                if continent != current_location:
                    current_location = continent
                print ('running', continent, damage_class, ': ', j, '/', length)
            ### need to create reverse dictionary to find correct j
            meanLRs = int_vals_list [j]
            std_devs = std_devs_list[j]
            # return list of bin index values for each intensity value used to calulcate a probability
            bin_index_list = get_bin_index(int_bins, int_mp_vals, int_mes_types, damage_class)
            # vulnerability id can be found with either taxonomy or node id 
            vuln_id = vuln_dict[(continent, damage_class)]
            # create vulnerability file with vulnerability ids, correct intensity bin indexes and damage bin indexes
            vuln_data = create_vuln_dict (vuln_id, bin_index_list, damage_bins)
            vuln_temp_df = pd.DataFrame(vuln_data)

            # function compute_probs() computes probabilities using beta distribution
            probs_data = compute_probs(int_vals, int_mp_vals, mean_LRs, std_devs, damage_bins_list)
            probs_df = pd.DataFrame(probs_data)

            vuln_df = pd.concat([vuln_temp_df, probs_df], axis = 1)        
            vuln_df.to_csv(dict_file, index=False, header=header)       
            header = False
        print (t_zero)
        print(time.time() - t_one)

kwargs = vars(parser.parse_args())
main(**kwargs)
