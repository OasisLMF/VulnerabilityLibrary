import csv
import os
import pandas as pd
import xml.etree.ElementTree as ET
import itertools
import numpy as np
from scipy import interpolate
from scipy.stats import beta

# Intensity Type is root[0][i][0].attrib['imt']
# Taxonomy is root[0][i].attrib['id']
# Intensity is root[0][i][0].text
# Mean Loss Ratio is root[0][i][1].text
# Coefficient of Variation is root[0][i][2].text

def directories():
    rootdir = "./global_vulnerability_model"
    location_dict = {}
    count = 0
    coverage_type = 'Structural'
    for subdir, dirs, files in os.walk(rootdir):
        for file in files:
            subdir = subdir.replace('\\', '/')
            filepath = subdir + '/' + file
            if filepath.endswith("vulnerability_structural.xml"):
                location = subdir.replace('./global_vulnerability_model/', '').replace('/', ' ').split()
                location_dict [location[0], location[1]] = filepath
                count += 1
            if count > 0:
                break
    return location_dict, coverage_type

def generate_footprint(location_list, coverage_type):
    vuln_ids = {}
    cur_vuln_id = 1
    for (continent, country) in location_list:
        pathway = location_list[(continent, country)]
        tree = ET.parse(pathway)
        root = tree.getroot()

        for i in range (len(root[0])-1):
            int_mes_type = root[0][i+1][0].attrib['imt']
            taxonomy = root[0][i+1].attrib['id']
            if (continent, country, int_mes_type, taxonomy) not in vuln_ids:
                vuln_ids[(continent, country, int_mes_type, taxonomy)] = cur_vuln_id
                cur_vuln_id += 1
            # for j, (intensity, MLR, CoV) in enumerate (zip(root[0][i+1][0].text.strip().split(' '), root[0][i+1][1].text.strip().split(' '), root[0][i+1][2].text.strip().split(' '))):
            for j, each in enumerate(root[0][i+1][0].text.strip().split(' ')):
                for k in np.linspace(0, 1, num=10, endpoint=True).round(1):
                    rec = {
                        "ValuationID": vuln_ids[(continent, country, int_mes_type, taxonomy)],
                        "IntensityBinID": j+1,
                        "DamageBinID": k
                        }
                    yield rec

def generate_vuln_ids(location_list):
    vuln_ids = {}
    cur_vuln_id = 1
    for (continent, country) in location_list:
        pathway = location_list[(continent, country)]
        tree = ET.parse(pathway)
        root = tree.getroot()

        for i in range (len(root[0])-1):
            int_mes_type = root[0][i+1][0].attrib['imt']
            taxonomy = root[0][i+1].attrib['id']
            if (continent, country) not in vuln_ids:
                vuln_ids[(continent, country, int_mes_type, taxonomy)] = cur_vuln_id
                cur_vuln_id += 1
                id_dict = {
                    "ID": vuln_ids[(continent, country, int_mes_type, taxonomy)],
                    "Continent": continent,
                    "Country": country,
                    "IntensityMeasurementType": int_mes_type,
                    "Taxonomy": taxonomy
                }
                yield id_dict
            
def create_bin_dict():
    with open('./GEM/intensity_bins.txt') as bins_file:
        int_val_lb = [float(0)]
        int_val_ub = []
        int_val_mp = []
        for line in bins_file:
            line = line.replace('\n', '')
            if line:
                int_val_lb.append(float(line))
                int_val_ub.append(float(line))
        int_val_ub.append(float (int_val_lb[-1]))
        for i, (j, k) in enumerate (zip (int_val_lb, int_val_ub)):
            int_val_mp.append((j+k) / 2)
            int_bin_dict = {'bin_from': int_val_lb, 'bin_to': int_val_ub, 'interpolation': int_val_mp}
    int_df = pd.DataFrame(int_bin_dict)
    int_df.to_csv('./GEM/int_bin_dict.csv', index=True, index_label='bin_index')

def generate_bins(df, location_list):
    # create_bin_dict()
    damage_bins = np.linspace(0, 1, num=100, endpoint=True)
    damage_bins = np.append (damage_bins[0], damage_bins)
    damage_bins = np.append(damage_bins, damage_bins[-1]).round(3)

    a=0
    b=1

    for (continent, country) in location_list:
        pathway = location_list[(continent, country)]
        tree = ET.parse(pathway)
        root = tree.getroot()
        for i in range (len(root[0])-1):
            int_vals = []
            mean_LRs = []
            std_dev_vals = []
            beta_params = []
            # for j, (intensity, meanLR, CoV, m, n) in enumerate (zip(root[0][i+1][0].text.strip().split(' '), root[0][i+1][1].text.strip().split(' '), root[0][i+1][2].text.strip().split(' '), int_val_lb, int_val_ub)):
            for intensity, meanLR, CoV in zip(root[0][i+1][0].text.strip().split(' '), root[0][i+1][1].text.strip().split(' '), root[0][i+1][2].text.strip().split(' ')):
                meanLR = float (meanLR)
                intensity = float (intensity)
                CoV = float (CoV)

                int_vals.append (intensity)
                mean_LRs.append (meanLR)
                std_dev_val = (meanLR * CoV)
                std_dev_vals.append(meanLR * CoV)

            int_vs_mean = interpolate.interp1d(int_vals, mean_LRs, kind='cubic')
            int_vs_std= interpolate.interp1d(int_vals, std_dev_vals, kind='cubic')
            interp_mean = int_vs_mean (int_vals)
            interp_std_dev = int_vs_std(int_vals)
            # def damage_probs()
            damage_bin_list = np.linspace(0,1,100, endpoint=True)
            for j, (mean_val, std_dev_val) in enumerate (zip (interp_mean, interp_std_dev)):
                alpha_val = (mean_val-a)/(b-a) * ((mean_val*(1-mean_val)/std_dev_val**2) - 1)
                beta_val = alpha_val * (1-mean_val) / mean_val
                
                # beta function automatically runs has start and end interval from 0 to 1
                vals = beta.cdf(damage_bin_list, alpha_val, beta_val)
                cum_diff_vals = np.diff(vals, axis=0)
                cum_diff_vals = np.append(0, cum_diff_vals)
                df['intensity_bin{index_no}'.format(index_no=j)] = cum_diff_vals
                #for i, prob in enumerate(cum_diff_vals):
                    #df['probability{index_no}'.format(index_no=j)] = prob
                #yield from new_prob_col(j, df,cum_diff_vals)

def create_damage_bins():
    damage_prob = {}
    damage_bins = np.linspace(0, 1, num=100, endpoint=True)
    damage_bins = np.append (damage_bins[0], damage_bins)
    damage_bins = np.append(damage_bins, damage_bins[-1]).round(3)
    for i in range (1, len(damage_bins)-1):
        damage_prob = {'damage_bin_index': i, 'bin_from': damage_bins[i-1], 'bin_to': damage_bins[i]}
        #'probability{index_no}'.format(index_no=j): prob}
        yield damage_prob

def main():
    directory = directories()
    location_list = directory [0]
    coverage_type = directory [1]
    init_bin_dict = create_damage_bins()
    df = pd.DataFrame(init_bin_dict)
    # print(df.head(50))
    generate_bins(df, location_list)
    # print (df.head(30))
    # print (df2.head(30))
    # df2 = pd.DataFrame(damage_bin_dict)
    # df = pd.concat([df2, df])
    df.to_csv('./GEM/dam_bin_dict.csv', index=False)
    # df_footrpint = generate_footprint(location_list, coverage_type)
    # df = pd.DataFrame(df_footrpint)
    # df = df.head(10000)
    # df_vuln_ids = generate_vuln_ids(location_list)
    # df2 = pd.DataFrame(df_vuln_ids)
    # df2 = df2.head(10000)
    # df.to_csv('GEM/footprint.csv', index=False)
    # df2.to_csv('GEM/vuln_ids.csv', index=False)

main()

""" for (continent, country) in location_list:
        pathway = location_list[(continent, country)]
        tree = ET.parse(pathway)
        root = tree.getroot()
    
        for i in range (len(root[0])-1):
            int_vals = []
            mean_LRs = []
            cov_vals = []
            for intensity, meanLR, CoV in zip(root[0][i+1][0].text.strip().split(' '), root[0][i+1][1].text.strip().split(' '), root[0][i+1][2].text.strip().split(' ')):
                int_vals.append (float(intensity))
                mean_LRs.append (float(meanLR))
                cov_vals.append(float(CoV))
            interp_cov_val = interpolate.interp1d(int_vals, cov_vals, kind = 'cubic') """